{"cells":[{"cell_type":"code","source":["# Required imports\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.mllib.recommendation import ALS, MatrixFactorizationModel\nfrom pyspark.sql import Row\nfrom pyspark.sql.types import *\n\nimport math\nimport numpy as np\nimport pandas as pd\nimport time"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["# Location of our data\nratings_loc = '/FileStore/tables/ratings.csv'\nmovies_loc = '/FileStore/tables/movies.csv'"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["def getDataframe(file_location):\n  \"\"\"\n  Generate a dataframe from a location in the databricks environment\n  \"\"\"\n  # File location and type\n  file_type = \"csv\"\n\n  # CSV options\n  infer_schema = \"false\"\n  first_row_is_header = \"true\"\n  delimiter = \",\"\n\n  # The applied options are for CSV files. For other file types, these will be ignored.\n  return spark.read.format(file_type) \\\n    .option(\"inferSchema\", infer_schema) \\\n    .option(\"header\", first_row_is_header) \\\n    .option(\"sep\", delimiter) \\\n    .load(file_location)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["# Load the data\nratings = getDataframe(ratings_loc)\nmovies = getDataframe(movies_loc)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["### Preprocessing the data for the model"],"metadata":{}},{"cell_type":"code","source":["# Reload the data\nmovie_rating = sc.textFile(ratings_loc)\nmovies_list = sc.textFile(movies_loc)\n\n# Remove the timestamp column from the ratings data\nheader = movie_rating.take(1)[0]\nrating_data = movie_rating \\\n    .filter(lambda line: line!=header) \\\n    .map(lambda line: line.split(\",\")) \\\n    .map(lambda tokens: (int(tokens[0]), int(tokens[1]), float(tokens[2]))) \\\n    .cache()\n\n# Remove the genre column from the movies data\nheader = movies_list.take(1)[0]\nmovies_data = movies_list \\\n    .filter(lambda line: line!=header) \\\n    .map(lambda line: line.split(\",\")) \\\n    .map(lambda tokens: (int(tokens[0]), str(tokens[1]))) \\\n    .cache()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["# Splitting the dataframe into a training and a test part. \ntraining, validation, test = rating_data.randomSplit([0.8, 0.2, 0.2], seed=12345)\n\ntraining.cache()\nvalidation.cache()\ntest.cache()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">6</span><span class=\"ansired\">]: </span>PythonRDD[24] at RDD at PythonRDD.scala:51\n</div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["### Train the Alternative Least Squares model including hyperparameter tuning"],"metadata":{}},{"cell_type":"code","source":["def train_ALS(train_data, validation_data, maxIters, regParams, ranks):\n  \n    # initial values\n    min_error = float('inf')\n    best_iters = -1\n    best_rank = -1\n    best_regularization = 0\n    best_model = None\n    \n    for iteration in maxIters: # Loop through all iteration possibilities\n      for rank in ranks: # Loop through all rank possibilities\n        for reg in regParams: # Loop through all lambda possibilities\n          \n          # Record the start time of a run\n          start = time.time() \n          \n          # Train ALS model\n          model = ALS.train(ratings=train_data, iterations=iteration, rank=rank, lambda_=reg, seed=12345)\n          \n          # Make predictions\n          valid_data = validation_data.map(lambda p: (p[0], p[1]))\n          predictions = model.predictAll(valid_data).map(lambda r: ((r[0], r[1]), r[2]))\n          \n          # Combine the ratings and the predictions\n          ratings_predicts = validation_data.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n            \n          # Get the Root Mean Square Error\n          MSE = ratings_predicts.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n          error = math.sqrt(MSE)\n        \n          # Calculate the time elapsed in this run\n          elapsed = time.time() - start\n          \n          print('{} latent factors with max iterations = {} and regularization = {}: validation RMSE is {}. Duration: {} seconds'\\\n                .format(rank, iteration, reg, error, elapsed))\n          \n          # Check if the current run is the best \n          if error < min_error:\n            min_error = error\n            best_iters = iteration\n            best_rank = rank\n            best_regularization = reg\n            best_model = model\n  \n    print('\\nThe best model has {} latent factors, {} max iterations and regularization = {}'\\\n          .format(best_rank, best_iters, best_regularization))\n    \n    return best_model"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["### Hyperparameter tuning for Alternative Least Squares\n1. We define some parameter configurations for the function to run through\n2. We train the ALS model for every possible combination of configurations\n3. The function returns the model with the ideal combination of parameters\n4. We save the model so we can easily use it later"],"metadata":{}},{"cell_type":"code","source":["# Hyper-param config\nnum_iterations = [10, 15, 20, 25]\nranks = [10, 15, 20, 25, 30]\nreg_params = [0.01, 0.05, 0.1, 0.2, 0.3]\n\n# Grid search and select best model\nresult = train_ALS(training, validation, num_iterations, reg_params, ranks)\nbest_model = result\n\n# Save the model so we can use it later\nbest_model.save(sc, \"/model/ALS\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-2876626853650186&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      9</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     10</span> <span class=\"ansired\"># Save the model so we can use it later</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 11</span><span class=\"ansiyellow\"> </span>best_model<span class=\"ansiyellow\">.</span>save<span class=\"ansiyellow\">(</span>sc<span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;/model/ALS&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/mllib/util.py</span> in <span class=\"ansicyan\">save</span><span class=\"ansiblue\">(self, sc, path)</span>\n<span class=\"ansigreen\">    404</span>         <span class=\"ansigreen\">if</span> <span class=\"ansigreen\">not</span> isinstance<span class=\"ansiyellow\">(</span>path<span class=\"ansiyellow\">,</span> basestring<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    405</span>             <span class=\"ansigreen\">raise</span> TypeError<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;path should be a basestring, got type %s&quot;</span> <span class=\"ansiyellow\">%</span> type<span class=\"ansiyellow\">(</span>path<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 406</span><span class=\"ansiyellow\">         </span>self<span class=\"ansiyellow\">.</span>_java_model<span class=\"ansiyellow\">.</span>save<span class=\"ansiyellow\">(</span>sc<span class=\"ansiyellow\">.</span>_jsc<span class=\"ansiyellow\">.</span>sc<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> path<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    407</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    408</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">   1255</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1256</span>         return_value = get_return_value(\n<span class=\"ansigreen\">-&gt; 1257</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansigreen\">   1258</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1259</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     61</span>     <span class=\"ansigreen\">def</span> deco<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     62</span>         <span class=\"ansigreen\">try</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 63</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">return</span> f<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     64</span>         <span class=\"ansigreen\">except</span> py4j<span class=\"ansiyellow\">.</span>protocol<span class=\"ansiyellow\">.</span>Py4JJavaError <span class=\"ansigreen\">as</span> e<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     65</span>             s <span class=\"ansiyellow\">=</span> e<span class=\"ansiyellow\">.</span>java_exception<span class=\"ansiyellow\">.</span>toString<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py</span> in <span class=\"ansicyan\">get_return_value</span><span class=\"ansiblue\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansigreen\">    326</span>                 raise Py4JJavaError(\n<span class=\"ansigreen\">    327</span>                     <span class=\"ansiblue\">&quot;An error occurred while calling {0}{1}{2}.\\n&quot;</span><span class=\"ansiyellow\">.</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 328</span><span class=\"ansiyellow\">                     format(target_id, &quot;.&quot;, name), value)\n</span><span class=\"ansigreen\">    329</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    330</span>                 raise Py4JError(\n\n<span class=\"ansired\">Py4JJavaError</span>: An error occurred while calling o5706.save.\n: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory dbfs:/model/ALS/metadata already exists\n\tat org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)\n\tat org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil.assertConf(SparkHadoopWriter.scala:287)\n\tat org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:71)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1096)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:375)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1094)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1067)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:375)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1032)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:958)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:375)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:957)\n\tat org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1516)\n\tat org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1495)\n\tat org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1495)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:375)\n\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1495)\n\tat org.apache.spark.mllib.recommendation.MatrixFactorizationModel$SaveLoadV1_0$.save(MatrixFactorizationModel.scala:367)\n\tat org.apache.spark.mllib.recommendation.MatrixFactorizationModel.save(MatrixFactorizationModel.scala:205)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n</div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["### Test the model with the test dataset"],"metadata":{}},{"cell_type":"code","source":["# Load the model\nmodel = MatrixFactorizationModel.load(sc, \"/model/ALS\")\n\n# Make a prediction using test data\ntest_data = test.map(lambda p: (p[0], p[1]))\npredictions = model.predictAll(test_data).map(lambda r: ((r[0], r[1]), r[2]))\n\n# Combine the ratings and the predictions\nratings_predicts = test.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n\n# Get the Root Mean Square Error\nMSE = ratings_predicts.map(lambda r: (r[1][0] - r[1][1])**2).mean()\nerror = math.sqrt(MSE)\n\nprint('The out-of-sample RMSE of rating predictions is', round(error, 4))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(&apos;The out-of-sample RMSE of rating predictions is&apos;, 0.9067)\n</div>"]}}],"execution_count":13},{"cell_type":"markdown","source":["### Recommending N movies for a specific user"],"metadata":{}},{"cell_type":"code","source":["def getRecommendation(userId, n_recommendations=10):\n    model = MatrixFactorizationModel.load(sc, \"/model/ALS\")\n\n    # Find movieIds of rated movies by user x\n    rated_movies = ratings.filter(ratings.userId == userId).select(\"movieId\").collect()\n    \n    # Get the list of movies without the rated movies by user x\n    movieId_list = []\n    for movie in rated_movies:\n      movieIds = movies \\\n          .filter(movies.movieId == movie.movieId) \\\n          .select('movieId') \\\n          .rdd \\\n          .map(lambda r: r[0]) \\\n          .collect()\n      movieId_list.extend(movieIds)\n     \n    movieId_list = list(set(movieId_list))\n    \n    candidates = movies.rdd \\\n        .map(lambda r: r[0]) \\\n        .distinct() \\\n        .filter(lambda x: x not in movieId_list) \\\n        .map(lambda x: (userId, x))\n    \n    # Predict the movies that should be recommended to user x\n    predictions = model.predictAll(candidates).map(lambda r: (r[1], r[2]))\n\n    # Get the top N\n    topn_rows = predictions.sortBy(lambda r: r[1], ascending=False).take(n_recommendations)\n    topn_ids = [r[0] for r in topn_rows]\n\n    # Return the top N recommended movies\n    return movies.filter(movies.movieId.isin(topn_ids)).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"code","source":["display(getRecommendation(10))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>movieId</th><th>title</th><th>genres</th></tr></thead><tbody><tr><td>3216</td><td>Vampyros Lesbos (Vampiras, Las) (1971)</td><td>Fantasy|Horror|Thriller</td></tr><tr><td>5059</td><td>Little Dieter Needs to Fly (1997)</td><td>Documentary</td></tr><tr><td>7074</td><td>Navigator, The (1924)</td><td>Comedy</td></tr><tr><td>8609</td><td>Our Hospitality (1923)</td><td>Comedy</td></tr><tr><td>31547</td><td>Lessons of Darkness (Lektionen in Finsternis) (1992)</td><td>Documentary|War</td></tr><tr><td>83318</td><td>Goat, The (1921)</td><td>Comedy</td></tr><tr><td>83359</td><td>Play House, The (1921)</td><td>Comedy</td></tr><tr><td>83411</td><td>Cops (1922)</td><td>Comedy</td></tr><tr><td>92494</td><td>Dylan Moran: Monster (2004)</td><td>Comedy|Documentary</td></tr><tr><td>97957</td><td>Excision (2012)</td><td>Crime|Drama|Horror|Thriller</td></tr></tbody></table></div>"]}}],"execution_count":16},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":17}],"metadata":{"name":"3-latent-factor-based","notebookId":1797887971437590},"nbformat":4,"nbformat_minor":0}
