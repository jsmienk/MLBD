{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yahtzee\n",
    "\n",
    "__Fully Connected Networks__\n",
    "\n",
    "_By Marnick van der Arend & Jeroen Smienk_\n",
    "\n",
    "![Yahtzee](yahtzee.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "__MODEL_PATH = 'yahtzee-models'\n",
    "__TENSOR_LOG_DIR = 'yahtzee-logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Let's start with looking at the provided dataset:\n",
    "\n",
    "It consists of 5832 'dice throws' and the label that describes that type of throw.\n",
    "\n",
    "The existing Yahtzee labels are: `nothing`, `small-straight`, `three-of-a-kind`, `large-straight`,\n",
    " `full-house`, `four-of-a-kind`, and `yathzee`.\n",
    " \n",
    " Name | Description\n",
    "--- | ---\n",
    "3-of-a-kind | Three dice the same\n",
    "4-of-a-kind | Four dice the same\n",
    "Full-house | Three of one number and two of another\n",
    "Small-straight | Four sequential dice\n",
    "Large-straight | Five sequential dice\n",
    "Yahtzee | All five dice the same\n",
    "Nothing | None of the above combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dice1</th>\n",
       "      <th>dice2</th>\n",
       "      <th>dice3</th>\n",
       "      <th>dice4</th>\n",
       "      <th>dice5</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>small-straight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dice1  dice2  dice3  dice4  dice5           label\n",
       "0      3      6      6      2      5         nothing\n",
       "1      3      6      1      3      4         nothing\n",
       "2      2      2      5      5      3         nothing\n",
       "3      1      3      6      6      1         nothing\n",
       "4      1      4      6      3      5  small-straight"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('yahtzee-dataset.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the labels are distributed in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nothing            0.663237\n",
       "three-of-a-kind    0.153635\n",
       "small-straight     0.094136\n",
       "full-house         0.037894\n",
       "large-straight     0.030521\n",
       "four-of-a-kind     0.019890\n",
       "yathzee            0.000686\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts() / len(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that 66.3% of all data is `nothing` throws. This makes sense of course because how harder the dice throws get, the less chance exists they occur.\n",
    "\n",
    "The most difficult throw (`yahtzee`) only occurs 0.069%! This might make it hard for any of our models to really learn what a `yahtzee` throw is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "\n",
    "In order to classify these categorical labels, we have to 'one-hot encode' them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dice1</th>\n",
       "      <th>dice2</th>\n",
       "      <th>dice3</th>\n",
       "      <th>dice4</th>\n",
       "      <th>dice5</th>\n",
       "      <th>label_four-of-a-kind</th>\n",
       "      <th>label_full-house</th>\n",
       "      <th>label_large-straight</th>\n",
       "      <th>label_nothing</th>\n",
       "      <th>label_small-straight</th>\n",
       "      <th>label_three-of-a-kind</th>\n",
       "      <th>label_yathzee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dice1  dice2  dice3  dice4  dice5  label_four-of-a-kind  label_full-house  \\\n",
       "0      3      6      6      2      5                     0                 0   \n",
       "1      3      6      1      3      4                     0                 0   \n",
       "2      2      2      5      5      3                     0                 0   \n",
       "3      1      3      6      6      1                     0                 0   \n",
       "4      1      4      6      3      5                     0                 0   \n",
       "5      4      1      4      3      1                     0                 0   \n",
       "6      4      4      4      6      2                     0                 0   \n",
       "7      3      2      5      6      3                     0                 0   \n",
       "8      3      4      3      6      2                     0                 0   \n",
       "9      3      3      1      5      4                     0                 0   \n",
       "\n",
       "   label_large-straight  label_nothing  label_small-straight  \\\n",
       "0                     0              1                     0   \n",
       "1                     0              1                     0   \n",
       "2                     0              1                     0   \n",
       "3                     0              1                     0   \n",
       "4                     0              0                     1   \n",
       "5                     0              1                     0   \n",
       "6                     0              0                     0   \n",
       "7                     0              1                     0   \n",
       "8                     0              1                     0   \n",
       "9                     0              1                     0   \n",
       "\n",
       "   label_three-of-a-kind  label_yathzee  \n",
       "0                      0              0  \n",
       "1                      0              0  \n",
       "2                      0              0  \n",
       "3                      0              0  \n",
       "4                      0              0  \n",
       "5                      0              0  \n",
       "6                      1              0  \n",
       "7                      0              0  \n",
       "8                      0              0  \n",
       "9                      0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_df = pd.get_dummies(df, prefix=['label'])\n",
    "one_hot_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can train any model, we have to split the data and the labels into X and Y after shuffling them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dice1</th>\n",
       "      <th>dice2</th>\n",
       "      <th>dice3</th>\n",
       "      <th>dice4</th>\n",
       "      <th>dice5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4560</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dice1  dice2  dice3  dice4  dice5\n",
       "379       4      4      3      3      1\n",
       "2417      4      3      5      6      2\n",
       "228       5      3      3      1      5\n",
       "45        1      1      2      4      3\n",
       "4560      1      3      1      2      6"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_shuffled_xy(one_hot_df):\n",
    "    shuffled = one_hot_df.sample(frac=1.)\n",
    "    return shuffled.iloc[:,:5].copy(), shuffled.iloc[:,5:].copy()\n",
    "\n",
    "X, Y = get_shuffled_xy(one_hot_df)\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also split the dataset into a 85:15 split for training and validating the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_split(x, y, frac):\n",
    "    split = int(len(x.index) * frac)\n",
    "    return x.iloc[:split], y.iloc[:split], x.iloc[split:], y.iloc[split:]\n",
    "\n",
    "X_train, Y_train, X_valid, Y_valid = get_validation_split(X, Y, .85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_split(x_train, y_train, frac):\n",
    "    split = int(len(x_train.index) * frac)\n",
    "    return x_train.iloc[:split], y_train.iloc[:split], x_train.iloc[split:], y_train.iloc[split:]\n",
    "    \n",
    "X_train, Y_train, X_test, Y_test = get_validation_split(X_train, Y_train, .85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split X (train, test, validation): (4213, 5) (744, 5) (875, 5)\n",
      "Split Y (train, test, validation): (4213, 7) (744, 7) (875, 7)\n"
     ]
    }
   ],
   "source": [
    "print('Split X (train, test, validation):', X_train.shape, X_test.shape, X_valid.shape)\n",
    "print('Split Y (train, test, validation):', Y_train.shape, Y_test.shape, Y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function that returns a random batch of a certain size. This batch is used in training to train faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data, labels, batch_size):\n",
    "    x_batch = data.sample(frac=batch_size / len(data.index))\n",
    "    return x_batch, labels.loc[x_batch.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "We designed several models:\n",
    "\n",
    "_Note: all models have a last layers without an activation function, because the SoftMax is done in the cross entropy calculation._\n",
    "\n",
    "rank | name | layers | score\n",
    "--- | --- | --- | ---\n",
    "5 | model_8 | (64, Tanh, Drop=.2) (128, Tanh, Drop=.3) (256, Tanh, Drop=.4) (512, Tanh, Drop=.5) (64, Tanh) | 0.93714285\n",
    "4 | model_7 | (64, ReLU) (128, ReLU) (256, ReLU) (512, ReLU, Drop=.3) (64, ReLU) | 0.94057140\n",
    "3 | model_6 | (200, Tanh) (300, Tanh) (600, Tanh) | ±0.97\n",
    "1 | model_5_2 | (600, Tanh, Drop=.3) (300, Tanh, Drop=.3) (200, Tanh, Drop=.3) | ±0.976\n",
    "2 | model_5 | (600, Tanh) (300, Tanh) (200, Tanh) | 0.97942860\n",
    "6 | model_4 | (128, Tanh) (64, Tanh) (32, Tanh) | 0.87771430\n",
    "7 | model_3 | (12, ReLU) (24, ReLU) (48, ReLU, Drop=.1) (96, ReLU) | 0.73028570\n",
    "8 | model_2 | (128, ReLU) (64, ReLU) (32, ReLU) | 0.82400000\n",
    "9 | model_1 | (128, Sigmoid) | ±0.65\n",
    "\n",
    "The best model uses dropout to prevent overfitting and the ReLU activation function which proved to perform better.\n",
    "\n",
    "### Metric Graphs\n",
    "\n",
    "__Legend:__\n",
    "\n",
    "- Model 1: BLUE\n",
    "- Model 2: RED\n",
    "- Model 3: LIGHT BLUE\n",
    "- Model 4: PINK\n",
    "- Model 5: GREEN\n",
    "- Model 6: GRAY\n",
    "- Model 7: ORANGE\n",
    "- Model 8: ORANGE\n",
    "\n",
    "#### Batch Accuracy Graph\n",
    "\n",
    "![Batch Accuracy](yahtzee-acc.png)\n",
    "\n",
    "#### Batch Loss Graph\n",
    "\n",
    "![Batch Loss](yahtzee-loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_1(x, output_shape):\n",
    "    \"\"\"\n",
    "    Single hidden layer with 128 neurons and Sigmoid activation function.\n",
    "    \"\"\"\n",
    "    l_1 = tf.layers.dense(x, units=128, activation=tf.nn.sigmoid)\n",
    "    return tf.layers.dense(l_1, units=output_shape, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_2(x, output_shape):\n",
    "    \"\"\"\n",
    "    Three hidden layers with different amounts of neurons and relu activation functions.\n",
    "    \"\"\"\n",
    "    l_1 = tf.layers.dense(x, units=128, activation=tf.nn.relu)\n",
    "    l_2 = tf.layers.dense(l_1, units=64, activation=tf.nn.relu)\n",
    "    l_3 = tf.layers.dense(l_2, units=32, activation=tf.nn.relu)\n",
    "    return tf.layers.dense(l_3, units=output_shape, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_3(x, output_shape):\n",
    "    \"\"\"\n",
    "    Six hidden layers with different amounts of neurons and \n",
    "    relu activation functions and 2 dropout layers.\n",
    "    \"\"\"\n",
    "    l_1 = tf.layers.dense(x, units=12, activation=tf.nn.relu)\n",
    "    l_2 = tf.layers.dense(l_1, units=24, activation=tf.nn.relu)\n",
    "    l_3 = tf.layers.dense(l_2, units=48, activation=tf.nn.relu)\n",
    "    d_3 = tf.layers.dropout(l_3, rate=.1)\n",
    "    l_4 = tf.layers.dense(d_3, units=96, activation=tf.nn.relu)\n",
    "    return tf.layers.dense(l_4, units=output_shape, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_4(x, output_shape):\n",
    "    \"\"\"\n",
    "    Three hidden layers with different amounts of neurons and relu activation functions.\n",
    "    \"\"\"\n",
    "    l_1 = tf.layers.dense(x, units=128, activation=tf.nn.tanh)\n",
    "    l_2 = tf.layers.dense(l_1, units=64, activation=tf.nn.tanh)\n",
    "    l_3 = tf.layers.dense(l_2, units=32, activation=tf.nn.tanh)\n",
    "    return tf.layers.dense(l_3, units=output_shape, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_5(x, output_shape):\n",
    "    \"\"\"\n",
    "    High number of neurons in layers, decreasing per layer; no dropout; TanH activation.\n",
    "    \"\"\"\n",
    "    l_1 = tf.layers.dense(x, units=600, activation=tf.nn.tanh)\n",
    "    l_2 = tf.layers.dense(l_1, units=300, activation=tf.nn.tanh)\n",
    "    l_3 = tf.layers.dense(l_2, units=200, activation=tf.nn.tanh)\n",
    "    return tf.layers.dense(l_3, units=output_shape, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_5_2(x, output_shape):\n",
    "    \"\"\"\n",
    "    High number of neurons in layers, decreasing per layer; consistent dropout; TanH activation.\n",
    "    \"\"\"\n",
    "    l_1 = tf.layers.dense(x, units=600, activation=tf.nn.tanh)\n",
    "    d_1 = tf.layers.dropout(l_1, rate=.3)\n",
    "    l_2 = tf.layers.dense(d_1, units=300, activation=tf.nn.tanh)\n",
    "    d_2 = tf.layers.dropout(l_2, rate=.3)\n",
    "    l_3 = tf.layers.dense(d_2, units=200, activation=tf.nn.tanh)\n",
    "    d_3 = tf.layers.dropout(l_3, rate=.3)\n",
    "    return tf.layers.dense(d_3, units=output_shape, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_6(x, output_shape):\n",
    "    \"\"\"\n",
    "    High number of neurons in layers, increasing per layer; no dropout; TanH activation.\n",
    "    \"\"\"\n",
    "    l_1 = tf.layers.dense(x, units=200, activation=tf.nn.tanh)\n",
    "    l_2 = tf.layers.dense(l_1, units=300, activation=tf.nn.tanh)\n",
    "    l_3 = tf.layers.dense(l_2, units=600, activation=tf.nn.tanh)\n",
    "    return tf.layers.dense(l_3, units=output_shape, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_7(x, output_shape):\n",
    "    \"\"\"\n",
    "    High number of neurons in layers; ReLU activation; single dropout layer.\n",
    "    \"\"\"\n",
    "    l_1 = tf.layers.dense(x, units=64, activation=tf.nn.relu)\n",
    "    l_2 = tf.layers.dense(l_1, units=128, activation=tf.nn.relu)\n",
    "    l_3 = tf.layers.dense(l_2, units=256, activation=tf.nn.relu)\n",
    "    l_4 = tf.layers.dense(l_3, units=512, activation=tf.nn.relu)\n",
    "    d_4 = tf.layers.dropout(l_4, rate=.3)\n",
    "    l_5 = tf.layers.dense(d_4, units=64, activation=tf.nn.relu)\n",
    "    return tf.layers.dense(l_5, units=output_shape, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_8(x, output_shape):\n",
    "    \"\"\"\n",
    "    More layers; TanH activation; increasing amount of dropout.\n",
    "    \"\"\"\n",
    "    l_1 = tf.layers.dense(x, units=64, activation=tf.nn.tanh)\n",
    "    d_1 = tf.layers.dropout(l_1, rate=.2)\n",
    "    l_2 = tf.layers.dense(d_1, units=128, activation=tf.nn.tanh)\n",
    "    d_2 = tf.layers.dropout(l_2, rate=.3)\n",
    "    l_3 = tf.layers.dense(d_2, units=256, activation=tf.nn.tanh)\n",
    "    d_3 = tf.layers.dropout(l_3, rate=.4)\n",
    "    l_4 = tf.layers.dense(d_3, units=512, activation=tf.nn.tanh)\n",
    "    d_4 = tf.layers.dropout(l_4, rate=.5)\n",
    "    l_5 = tf.layers.dense(d_4, units=64, activation=tf.nn.tanh)\n",
    "    return tf.layers.dense(l_5, units=output_shape, activation=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the placeholder for our 5-dice input and 7-class output and choose a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, X.shape[1]], name='x')\n",
    "y = tf.placeholder(tf.float32, shape=[None, Y.shape[1]], name='y')\n",
    "\n",
    "model_fn = model_5_2\n",
    "y_pred = model_fn(x, Y.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Test, Validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose an optimizer and define a loss functon and the accuracy metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=y_pred)\n",
    "loss_fn = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Optimizer minimizes the loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=.001).minimize(loss_fn)\n",
    "\n",
    "# Accuracy metric\n",
    "#   checks if the indices of the highest values in the real \n",
    "#   and predicted arrays are equal\n",
    "prediction = tf.equal(tf.argmax(y, axis=1), tf.argmax(y_pred, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model using a certain batch size and for a number of iterations while posting scalars to TensorBoard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing - i: 1  Accuracy: 0.63844085\n",
      "Testing - i: 51  Accuracy: 0.63844085\n",
      "Testing - i: 101  Accuracy: 0.63844085\n",
      "Testing - i: 151  Accuracy: 0.641129\n",
      "Testing - i: 201  Accuracy: 0.63844085\n",
      "Testing - i: 251  Accuracy: 0.64784944\n",
      "Testing - i: 301  Accuracy: 0.6357527\n",
      "Testing - i: 351  Accuracy: 0.6491935\n",
      "Testing - i: 401  Accuracy: 0.63978493\n",
      "Testing - i: 451  Accuracy: 0.6518817\n",
      "Testing - i: 501  Accuracy: 0.63709676\n",
      "Testing - i: 551  Accuracy: 0.6532258\n",
      "Testing - i: 601  Accuracy: 0.65994626\n",
      "Testing - i: 651  Accuracy: 0.66263443\n",
      "Testing - i: 701  Accuracy: 0.6814516\n",
      "Testing - i: 751  Accuracy: 0.68682796\n",
      "Testing - i: 801  Accuracy: 0.6989247\n",
      "Testing - i: 851  Accuracy: 0.7177419\n",
      "Testing - i: 901  Accuracy: 0.7405914\n",
      "Testing - i: 951  Accuracy: 0.78494626\n",
      "Testing - i: 1001  Accuracy: 0.79435486\n",
      "Testing - i: 1051  Accuracy: 0.8346774\n",
      "Testing - i: 1101  Accuracy: 0.8427419\n",
      "Testing - i: 1151  Accuracy: 0.83870965\n",
      "Testing - i: 1201  Accuracy: 0.8467742\n",
      "Testing - i: 1251  Accuracy: 0.87096775\n",
      "Testing - i: 1301  Accuracy: 0.8642473\n",
      "Testing - i: 1351  Accuracy: 0.87903225\n",
      "Testing - i: 1401  Accuracy: 0.87768817\n",
      "Testing - i: 1451  Accuracy: 0.8830645\n",
      "Testing - i: 1501  Accuracy: 0.88037634\n",
      "Testing - i: 1551  Accuracy: 0.9086022\n",
      "Testing - i: 1601  Accuracy: 0.89784944\n",
      "Testing - i: 1651  Accuracy: 0.88978493\n",
      "Testing - i: 1701  Accuracy: 0.9032258\n",
      "Testing - i: 1751  Accuracy: 0.9233871\n",
      "Testing - i: 1801  Accuracy: 0.9018817\n",
      "Testing - i: 1851  Accuracy: 0.91263443\n",
      "Testing - i: 1901  Accuracy: 0.92069894\n",
      "Testing - i: 1951  Accuracy: 0.922043\n",
      "Testing - i: 2001  Accuracy: 0.922043\n",
      "Testing - i: 2051  Accuracy: 0.92876345\n",
      "Testing - i: 2101  Accuracy: 0.922043\n",
      "Testing - i: 2151  Accuracy: 0.9395161\n",
      "Testing - i: 2201  Accuracy: 0.9341398\n",
      "Testing - i: 2251  Accuracy: 0.9422043\n",
      "Testing - i: 2301  Accuracy: 0.93682796\n",
      "Testing - i: 2351  Accuracy: 0.9516129\n",
      "Testing - i: 2401  Accuracy: 0.93682796\n",
      "Testing - i: 2451  Accuracy: 0.9354839\n",
      "Testing - i: 2501  Accuracy: 0.95564514\n",
      "Testing - i: 2551  Accuracy: 0.952957\n",
      "Testing - i: 2601  Accuracy: 0.9435484\n",
      "Testing - i: 2651  Accuracy: 0.952957\n",
      "Testing - i: 2701  Accuracy: 0.952957\n",
      "Testing - i: 2751  Accuracy: 0.97043014\n",
      "Testing - i: 2801  Accuracy: 0.9677419\n",
      "Testing - i: 2851  Accuracy: 0.9502688\n",
      "Testing - i: 2901  Accuracy: 0.9717742\n",
      "Testing - i: 2951  Accuracy: 0.96236557\n",
      "Testing - i: 3001  Accuracy: 0.9596774\n",
      "Testing - i: 3051  Accuracy: 0.9717742\n",
      "Testing - i: 3101  Accuracy: 0.97043014\n",
      "Testing - i: 3151  Accuracy: 0.9677419\n",
      "Testing - i: 3201  Accuracy: 0.96370965\n",
      "Testing - i: 3251  Accuracy: 0.9569892\n",
      "Testing - i: 3301  Accuracy: 0.9408602\n",
      "Testing - i: 3351  Accuracy: 0.952957\n",
      "Testing - i: 3401  Accuracy: 0.97043014\n",
      "Testing - i: 3451  Accuracy: 0.96505374\n",
      "Testing - i: 3501  Accuracy: 0.9798387\n",
      "Testing - i: 3551  Accuracy: 0.97849464\n",
      "Testing - i: 3601  Accuracy: 0.97849464\n",
      "Testing - i: 3651  Accuracy: 0.983871\n",
      "Testing - i: 3701  Accuracy: 0.9811828\n",
      "Testing - i: 3751  Accuracy: 0.9798387\n",
      "Testing - i: 3801  Accuracy: 0.98521507\n",
      "Testing - i: 3851  Accuracy: 0.983871\n",
      "Testing - i: 3901  Accuracy: 0.9825269\n",
      "Testing - i: 3951  Accuracy: 0.98521507\n",
      "Testing - i: 4001  Accuracy: 0.983871\n",
      "Testing - i: 4051  Accuracy: 0.98655915\n",
      "Testing - i: 4101  Accuracy: 0.98521507\n",
      "Testing - i: 4151  Accuracy: 0.98790324\n",
      "Testing - i: 4201  Accuracy: 0.9758065\n",
      "Testing - i: 4251  Accuracy: 0.9811828\n",
      "Testing - i: 4301  Accuracy: 0.9811828\n",
      "Testing - i: 4351  Accuracy: 0.98655915\n",
      "Testing - i: 4401  Accuracy: 0.9919355\n",
      "Testing - i: 4451  Accuracy: 0.98521507\n",
      "Testing - i: 4501  Accuracy: 0.98790324\n",
      "Testing - i: 4551  Accuracy: 0.98521507\n",
      "Testing - i: 4601  Accuracy: 0.983871\n",
      "Testing - i: 4651  Accuracy: 0.9811828\n",
      "Testing - i: 4701  Accuracy: 0.98655915\n",
      "Testing - i: 4751  Accuracy: 0.9892473\n",
      "Testing - i: 4801  Accuracy: 0.98655915\n",
      "Testing - i: 4851  Accuracy: 0.98521507\n",
      "Testing - i: 4901  Accuracy: 0.98521507\n",
      "Testing - i: 4951  Accuracy: 0.98521507\n",
      "Validation accuracy: [0.992]\n"
     ]
    }
   ],
   "source": [
    "iters = 5000\n",
    "train_batch_size = 100\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "session = tf.Session()\n",
    "with session:\n",
    "    session.run(init_op)\n",
    "\n",
    "    # Defining the metrics we want to log in TensorBoard\n",
    "    sum_loss_train = tf.summary.scalar('loss_train', loss_fn)\n",
    "    sum_loss_test = tf.summary.scalar('loss_test', loss_fn)\n",
    "    sum_acc_train = tf.summary.scalar('acc_train', accuracy)\n",
    "    sum_acc_test = tf.summary.scalar('acc_test', accuracy)\n",
    "    tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(os.path.join(__TENSOR_LOG_DIR, model_fn.__name__), session.graph)\n",
    "\n",
    "    # Start training for a certain number of iterations\n",
    "    for i in range(iters):\n",
    "        # Every iteration we get a random batch of the training data\n",
    "        x_batch, y_batch = get_batch(X_train, Y_train, train_batch_size)\n",
    "        # We train the model by providing the 'optimizer' variable to the run function.\n",
    "        # We also want to calculate the accuracy and loss TensorBoard metrics\n",
    "        loss_val, _, acc_val, sum_1, sum_2 = session.run([loss_fn, optimizer, accuracy, \n",
    "                                                          sum_loss_train, sum_acc_train], \n",
    "                                                         feed_dict={x: x_batch, y: y_batch})\n",
    "        # Write the metrics to TensorBoard\n",
    "        writer.add_summary(sum_1, global_step=i)\n",
    "        writer.add_summary(sum_2, global_step=i)\n",
    "\n",
    "        # Validate every 50 iterations\n",
    "        if i % 50 == 0:\n",
    "            # DO NOT PROVIDE THE 'optimzer' VARIABLE HERE\n",
    "            # ELSE THE MODEL WILL TRAIN ON THE TEST DATA\n",
    "            acc_val, sum_1, sum_2 = session.run([accuracy, sum_loss_test, sum_acc_test], \n",
    "                                                feed_dict={x: X_test, y: Y_test})\n",
    "            # Write the metrics to TensorBoard\n",
    "            writer.add_summary(sum_1, global_step=i)\n",
    "            writer.add_summary(sum_2, global_step=i)\n",
    "            print('Testing - i:', i+1, ' Accuracy:', acc_val)\n",
    "    \n",
    "\n",
    "    # Validate the model with unseen data\n",
    "    acc_val = session.run([accuracy], feed_dict={x: X_valid, y: Y_valid})\n",
    "    print('Validation accuracy:', acc_val)\n",
    "    \n",
    "    # Save the model\n",
    "    saver.save(session, '{}.ckpt'.format(os.path.join(__MODEL_PATH, model_fn.__name__, model_fn.__name__)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Saved Model\n",
    "\n",
    "We load the model that worked best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_load = model_5_2\n",
    "\n",
    "load_path = '{}.ckpt'.format(os.path.join(__MODEL_PATH, \n",
    "                                          model_to_load.__name__, \n",
    "                                          model_to_load.__name__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from yahtzee-models/model_5_2/model_5_2.ckpt\n",
      "Validation accuracy imported model_5_2: [0.9977143]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as saved_session:\n",
    "    tf.train.Saver().restore(saved_session, load_path)\n",
    "\n",
    "    # Validate the model with unseen data\n",
    "    acc_val = saved_session.run([accuracy], feed_dict={x: X_valid, y: Y_valid})\n",
    "\n",
    "    # Print test metrics\n",
    "    print('Validation accuracy imported {}: {}'.format(model_to_load.__name__, acc_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### Dataset\n",
    "\n",
    "- The dataset contains 5832 rows which is enough for this deep learning excersice.\n",
    "- The distribution of the labels may cause the model to not optimally learn the very rare throws like `yahtzee`.\n",
    "\n",
    "### Model\n",
    "\n",
    "#### Sizes\n",
    "\n",
    "#### Activation Functions\n",
    "\n",
    "We looked at Sigmoid, ReLU and TanH. Sigmoid performed less well than ReLU and TanH. To our surprise TanH worked best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
